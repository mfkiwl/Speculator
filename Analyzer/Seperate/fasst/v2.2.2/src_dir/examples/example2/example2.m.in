% This is an example of script for source separation of two speakers on an
% 8 channel anechoic mixture using FASST software.
%
% Speaker source images (i.e. signals captured by microphones) are 
% provided (src_imag_1_anechoic.wav and src_imag_2_anechoic.wav) and summed
% together to simulate a mixture.
% Input files have been generated with the roomsimove toolbox [1] 
% by simulating an 8-omnidirectional microphones array placed in the 
% center of a shoe box room with no reverberation for two different virtual
% speakers positions (one per speaker).
% In this example, microphone positions and speaker directions (i.e. azimuth
% / elevation) in the microphone array coordinate system are assumed to be known.
% Note : speaker directions can be estimated using an audio multichannel 
% source localization algorithm on the mixture (Multichannel BSS Locate [2]
% is an example of such software)
% 
% Parameters used to initialize FASST in this example:
% * Mixture type : convolutive.
% * Time-Frequency representation : STFT with 1024 frequency bins.
% * Source parameter Wex : Normally distributed random matrix (default init).
% * Source parameter Hex : Normally distributed random matrix (default init).
% * Source parameter A : Steering vector pointing to the main direction of arrival.
% * Source parameter adaptability : free, all previous parameters are
%   updated during the iterative EM process.
% * Number of EM iterations : 10
%
% PEASS backend [3](*)(**) is used to provide some separation quality
% measurements by comparing input sources images and FASST estimated sources
%
% [1] Roomsimove : Matlab toolbox for the computation of simulated room 
% impulse responses for moving sources.
% Authors : E. Vincent and DR Campbell
% https://members.loria.fr/EVincent/software-and-data/
%
% [2] Multi-Channel BSS Locate : A toolbox for source localization in 
% multi-channel convolutive audio mixtures. 
% Implemented by R. Lebarbenchon and E. Camberlein. 
% http://bass-db.gforge.inria.fr/bss_locate/#mbss_locate
%
% [3] PEASS : Matlab toolbox for perceptually-motivated objective evaluation
% of source separation algorithms.
% Valentin Emiya, Emmanuel Vincent, Niklas Harlander and Volker Hohmann,
% Subjective and objective quality assessment of audio source separation,
% IEEE Transactions on Audio, Speech and Language Processing, 2011, 19 (7),
% pp. 2046-2057.
% http://bass-db.gforge.inria.fr/peass/
%
% (*)  : Please follow readme guidelines to install PEASS backend.
% (**) : If this example was provided with windows installer, please
% update PEASS_BACK_END and PEASS_PATH variables in the following code 
% to correctly deal with your configuration.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Copyright 2018 Ewen Camberlein (INRIA), Romain Lebarbenchon (INRIA)
% This software is distributed under the terms of the GNU Public License
% version 3 (http://www.gnu.org/licenses/gpl.txt)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Cleaning
clear all;
close all;

%% ------------------------------------------------------------------------
%                      Paths management
%--------------------------------------------------------------------------

% Add FASST directory to PATH
FASST_MATLAB_DIR = '@FASST_MATLAB_DIR@';

if ~exist('fasst_writeXML', 'file')
    addpath(FASST_MATLAB_DIR);
end

% Add PEASS PATH to MATLAB
PEASS_BACK_END = @PEASS_BACK_END@;
PEASS_PATH = '@PEASS_PATH@';
if(PEASS_BACK_END ==1)
    addpath(genpath(PEASS_PATH));
    peassOutputDir = './peass/';
    mkdir(peassOutputDir);
end

% Add tools PATH to MATLAB
addpath('../tools')

% Create necessary folders
results_dir = 'results/'; % Results folder
tmp_dir    = 'temp/';     % Temporary folder (intermediate files generated by FASST)

if ~exist(results_dir, 'dir')
    mkdir(results_dir);
end
if ~exist(tmp_dir, 'dir')
    mkdir(tmp_dir);
end

%% ------------------------------------------------------------------------
%                           Mixture computation
%--------------------------------------------------------------------------

% Sampling frequency
fs = 16000; 

% Read source images (anechoic records simulated using roomsimove software) from disk
wavImagNames = {'src_imag_1_anechoic.wav','src_imag_2_anechoic.wav'}; % Sources images wav files sharing the same sampling frequency fs
for j=1:length(wavImagNames)
    [x_img(j,:,:),~] = audioread(wavImagNames{j});
end

% Compute mixture (x_mix) from source images (x_img)
x_mix = squeeze(sum(x_img,1)); 

% Write mixture on disk
mixture_wavname = [results_dir 'mixture.wav'];
audiowrite(mixture_wavname,x_mix,fs); 

%% ------------------------------------------------------------------------
%                   Mixture and audio scene information
%--------------------------------------------------------------------------

% Number of sources
J = length(wavImagNames); 

% Mixture number of samples and number of channels (I)
[nbSamples_Mix,I] = size(x_mix); 

% Microphones positions on the microphone array (cartesian coordinates)
micPos = [0.037 0.056 -0.038;
         -0.034 0.056 0.038;
         -0.056 0.037 -0.038;
         -0.056 -0.034 0.038;
         -0.037 -0.056 -0.038;
          0.034 -0.056 0.038;
          0.056 -0.037 -0.038;
          0.056 0.034 0.038];
    
% Estimated directions for each source (using mbss locate software)
estimatedDirections{1} = [-45,0];  % [azimuth, elevation] _degrees
estimatedDirections{2} = [45,0];   % [azimuth, elevation] _degrees

%% ------------------------------------------------------------------------
%            FASST Initialization (compute input xml file)
%--------------------------------------------------------------------------

disp([newline '> FASST initialization']);

% --- FASST general configuration (direct inputs for FASST)

transformType     = 'STFT';   % Time-frequency transform (STFT | ERB | ERBLET)
wlen              = 1024;     % Window length in samples (frame length in time domain) - should be multiple of 4 for STFT

nbin_ERB          = 32;      % Number of total frequency bins for ERB - ERB mandatory param
nbinPerERB_ERBLET = 1;       % Number of frequency bins per ERB for ERBLET (1 bin per ERB with 1600 kHz fs lead to nbin = 34 ) - ERBLET mandatory param

Niteration_EM     = 10;     % Number of iteration of EM algorithm for sources models estimation

% --- Initialization of models and FASST specific parameters for each source
N                 = ceil(nbSamples_Mix/wlen*2); % Number of frames
K                 = 32;                         % NFM rank (number of spectral patterns in the dictionary)

% --- Compute the number of frequency bins and the center of frequency bands / clean unused params with respect to chosen transform ---
[freqBandCenters_Hz, nbin, nbinPerERB_ERBLET, nbin_ERB] =  get_freqScaleParams(transformType,wlen,nbin_ERB,nbinPerERB_ERBLET,fs);

disp('>> User Params:');
disp(['   Transform:' transformType] );
disp(['     - wlen:' num2str(wlen) ]);
disp(['     - nbin:' num2str(nbin) ]);
disp(['     - nbin_ERB:' num2str(nbin_ERB) ]);
disp(['     - nbinPerERB_ERBLET:' num2str(nbinPerERB_ERBLET) ]);
disp(['   J (number of sources):' num2str(J) ]);
disp(['   K (NMF rank):' num2str(K) ]);

sources=[];
for j = 1:J   
    % Name of output audio file for source j
    sources{j}.name = ['EstimatedSource_',num2str(j)];
    
    % Type of mixture
    sources{j}.A.mixingType = 'conv';   % Convolutive mixture
    
    % Spatial model adaptability
    sources{j}.A.adaptability = 'free'; % Will be adapted by FASST

    % Spatial model initialization : Steering vector (frequency dependent) from source direction and microphones positions
    sources{j}.A.data = computeSteeringVectorFromDirection(estimatedDirections{j},micPos,freqBandCenters_Hz);
              
    % Spectral patterns (Wex) and time activation patterns applied to spectral patterns (Hex)
    % Adaptability of models
    sources{j}.Wex.adaptability = 'free'; % Will be adapted by FASST
    sources{j}.Hex.adaptability = 'free'; % Will be adapted by FASST

    % Initialization of models
    sources{j}.Wex.data = 0.75 * abs(randn(nbin, K)) + 0.25 * ones(nbin, K);
    sources{j}.Hex.data = 0.75 * abs(randn(K, N)) + 0.25 * ones(K, N);

    % Wiener filter parameters   
    sources{j}.wiener.a  = 0;    % a  : Over-substraction parameter (in dB) - Default value = 0 
    sources{j}.wiener.b  = 0;    % b  : Phase ponderation parameter (inside [0,1]) - Default value = 0 
    sources{j}.wiener.c1 = 0;    % c1 : Half-time width of the covariance smoothing window ( c1 >= 0)- Default value = 0 
    sources{j}.wiener.c2 = 0;    % c2 : Half-frequency width of the covariance smoothing window ( c2 >= 0)- Default value = 0 
    sources{j}.wiener.d  = -Inf; % d  : Thresholding parameter ( in dB, d <= 0)- Default value = -Inf 
end

% --- Write FASST_data structure in FASST input xml file

% Define FASST data structure
FASST_data.tfr_type   = transformType;
FASST_data.wlen       = wlen;
FASST_data.iterations = Niteration_EM;
FASST_data.sources    = sources;

% Write parameters to XML
xml_fname = [tmp_dir 'sources.xml'];
fasst_writeXML(xml_fname, FASST_data);

%% ------------------------------------------------------------------------
%                         Call FASST binaries
%--------------------------------------------------------------------------

disp([newline '> FASST execution']);

disp('>> Input time-frequency representation');
fasst_compute_mixture_covariance_matrix(mixture_wavname, xml_fname, tmp_dir)

disp('>> Refinement of sources models (EM algorithm)');
fasst_estimate_source_parameters(xml_fname, tmp_dir, [xml_fname '.new'])

disp('>> Computation of estimated sources');
fasst_estimate_sources(mixture_wavname, [xml_fname '.new'], tmp_dir, results_dir)

% Delete temporary folder
rmdir(tmp_dir,'s')

%% ------------------------------------------------------------------------
%                 Results evaluation with PEASS software
%--------------------------------------------------------------------------

if(PEASS_BACK_END)
    for j=1:J
        originalFiles = {...
            ['./' 'src_imag_' num2str(j) '_anechoic.wav'];...
            };
        estimateFile =  [results_dir sources{j}.name '.wav'];
        
        % Set options
        options.destDir = peassOutputDir;
        options.segmentationFactor = 1; % Increase this integer if you experienced "out of memory" problems
        
        % Call main function
        res = PEASS_ObjectiveMeasure(originalFiles,estimateFile,options);
        

        % Display results
        fprintf('************************\n');
        fprintf(['* EVALUATION FOR SOURCE' num2str(j) '*\n']);
        fprintf('************************\n');
        
        fprintf('************************\n');
        fprintf('* INTERMEDIATE RESULTS *\n');
        fprintf('************************\n');
        
        fprintf('The decomposition has been generated and stored in:\n');
        cellfun(@(s)fprintf(' - %s\n',s),res.decompositionFilenames);
        
        fprintf('The ISR, SIR, SAR and SDR criteria computed with the new decomposition are:\n');
        fprintf(' - SDR = %.1f dB\n - ISR = %.1f dB\n - SIR = %.1f dB\n - SAR = %.1f dB\n',...
            res.SDR,res.ISR,res.SIR,res.SAR);
        
        fprintf('The audio quality (PEMO-Q) criteria computed with the new decomposition are:\n');
        fprintf(' - qGlobal = %.3f\n - qTarget = %.3f\n - qInterf = %.3f\n - qArtif = %.3f\n',...
            res.qGlobal,res.qTarget,res.qInterf,res.qArtif);
        
        fprintf('*************************\n');
        fprintf('****  FINAL RESULTS  ****\n');
        fprintf('*************************\n');
        fprintf(' - Overall Perceptual Score: OPS = %.f/100\n',res.OPS)
        fprintf(' - Target-related Perceptual Score: TPS = %.f/100\n',res.TPS)
        fprintf(' - Interference-related Perceptual Score: IPS = %.f/100\n',res.IPS)
        fprintf(' - Artifact-related Perceptual Score: APS = %.f/100\n',res.APS);
    end
end